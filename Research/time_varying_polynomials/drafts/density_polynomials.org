#+OPTIONS: toc:nil
#+LATEX_HEADER: \usepackage[margin=0.85in]{geometry}
#+LATEX_HEADER: \newtheorem{theorem}{Theorem}[section]
#+LATEX_HEADER: \newtheorem{definition}[theorem]{Definition}
#+LATEX_HEADER: \newtheorem{lemma}[theorem]{Lemma}
#+LATEX_HEADER: \newtheorem{proof}[theorem]{Proof}
#+LATEX_HEADER: \newcommand{\onenorm}[1]{\left\lVert#1\right\rVert_1}
#+LATEX_HEADER: \newcommand{\inftynorm}[1]{\left\lVert#1\right\rVert_{\infty, [0, 1]}}
#+LATEX_HEADER: \newcommand{\lonenorm}[1]{\left\lVert#1\right\rVert_{L_1(0, 1)}}
#+LATEX_HEADER: \newcommand{\partlonenorm}[2]{\left\lVert#1\right\rVert_{L_1(#2)}}

# \bibliographystyle{plain}
#+TITLE: Convergence of the optimal polynomial solution
#+AUTHOR: Bachir El Khadir
 #+BEGIN_SRC emacs-lisp :exports none
(defun add-caption-header-and-center (caption header )
  (concat (format "org\n#+attr_html: :class center :width 300px\n#+ATTR_LATEX: :float nil\n#+caption: %s\n%s\n|-|" caption header)))
(defun add-caption-and-center (caption)
  (concat (format "org\n#+attr_html: :class center :width 300px\n#+caption: %s\n#+ATTR_LATEX:  :width 0.45\\textwidth :float nil" caption)))

#+END_SRC

#+RESULTS:
: add-caption-and-center


#+BEGIN_ABSTRACT
Given a continuum of linear minimization problems with time varying objective function $c(t)$ under linear constraint $A x(t) \le b$, SOS techniques allow us to find the best polynomial solution $P(t)$.

In this draft, we prove that as the degree of this polynomial gets larger, we converge to the overall optimal solution $x(t)$ in the $L_1$ sense.


- We first work on slightly smaller polyhedron $\mathcal P_{\alpha} = \{A x(t) \le b - \alpha\}$.
- we approximate the solution by a piece wise linear function $g(t)$
- then we find a polynomial that approximate uniformly $g(t)$ that stays in $\mathcal P_0$.
- we conclude by continuity of the optimal solution with respect to
 small perturbation of $b$.

#+END_ABSTRACT

* Notation

** $L_1$ Norm for vectors and functions

   For a vector $x \in \mathbb R^n$, $\onenorm{x} = \sum_{i=1}^n |x_i|$.
  
   For a function $f: [0, 1] \rightarrow \mathbb R^n$, $\lonenorm{f} = \int_0^1 \onenorm{f(t)} dt$
  
   $L_1([0, 1]) := L_1([0, 1], \mathbb R^d) = \{ f: \; [0, 1] \rightarrow \mathbb R^d,\; \lonenorm{f} < \infty\}$



** Time varying minimization problem  
Define the optimization problems:
  
      \begin{equation}
      \tag{Pb}
\begin{array}{ll@{}ll}
\text{minimize} & \langle c(t), x(t) \rangle & \\
\text{subject to}& A x(t) \le b
\end{array}
\end{equation}


  
\begin{equation}
\tag{$Pb_{\alpha}$}
\begin{array}{ll@{}ll}
\text{minimize} & \langle c(t), x(t) \rangle & \\
\text{subject to}& A x(t) \le b - \alpha
\end{array}
\end{equation}


\begin{equation}
\tag{$Pb_n$}
\begin{array}{ll@{}ll}
\text{minimize} & \int_0^1 \langle c(t), P(t) \rangle dt & \\
\text{subject to}& A P(t) \le b \\
& P \in \mathbb R_n[t]
\end{array}
\end{equation}


Call $x(t), x^{\alpha}(t)$ the solutions to $Pb$ and $Pb_{\alpha}$ respectively.

* Density of polynomials
  #+BEGIN_theorem 
For every $\varepsilon > 0, f \in L_1([0, 1], \mathbb R^n)$, there exists $P \in \mathbb R[t]$ such that $\lonenorm{f - P} \le \varepsilon$
  #+END_theorem

  #+BEGIN_theorem 
For every $\varepsilon > 0, f \in C_0([0, 1], \mathbb R^n)$, there exists $P \in \mathbb R[t]$ such that $\inftynorm{f - P} \le \varepsilon$
  #+END_theorem

  
* Continuity of the solution with respect to a perturbation of the constraints

    #+begin_definition
  $\mathcal P = \{x \in \mathbb R^n, \; Ax \le b\}$ a non degenerate (bounded) polyhedron, such that $x \in \mathcal P \implies \inftynorm{x} \le \mathcal D$
  
  $\mathcal P_{\alpha} = \{x \in \mathbb R^n, Ax \le b - \alpha \}$

  $A = \begin{pmatrix}A_1^T\\ \vdots \\A_d^T\end{pmatrix} \in \mathbb R^{d \times n}$,  $x = \begin{pmatrix}x_1\\ \vdots \\x_n\end{pmatrix}$,  $b = \begin{pmatrix}b_1\\ \vdots \\b_d\end{pmatrix}$.


  Recall that $x^{\alpha}$ is the solution to $\min_{\mathcal P_{\alpha}} \int_0^1 \langle c_t, x_t \rangle dt$,  and $x := x^{0}$
  #+end_definition


  Without loss of generality, by translating the space of $x$, *we assume that $\mathcal P$ contains a ball centered around 0*.

#+BEGIN_SRC python :session *PYTHON* :results file :exports results  :wrap (add-caption-and-center "Example polyhedron")
import matplotlib.pyplot as plt
plt.rcdefaults()

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.path as mpath
import matplotlib.lines as mlines
import matplotlib.patches as mpatches
from matplotlib.collections import PatchCollection


def label(xy, text):
    y = xy[1]
    plt.text(xy[0], y, text, ha="center", family='sans-serif', size=14)


fig, ax = plt.subplots()

patches = []


# add a Polygon
polygon = mpatches.RegularPolygon((0, 0), 5, 0.1, alpha=0.9, fill=True)
ax.add_patch(polygon)
label((0, 0), '$P_{\\alpha}$')

polygon = mpatches.RegularPolygon((0, 0), 5, 0.12, alpha=.3, facecolor='red',
fill=True)
ax.add_patch(polygon)
label((-0.01, 0.1), '$P_0$')


arrow = mpatches.Arrow(0.085, 0, .018, -.005, width=.01)
ax.add_patch(arrow)
label((0.095, 0.005), '$\\alpha$')


label((0.045, 0.01), '$0$')
ax.plot(0.045, 0.005,'x',markersize=10, markeredgecolor=(0,0,0), markerfacecolor='w', markeredgewidth=2)

plt.subplots_adjust(left=0, right=1, bottom=0, top=1)
plt.axis('equal')
plt.axis('off')

filename='polyhedron.png'
plt.savefig(filename)
filename
  #+END_SRC
  
  #+RESULTS:
  #+BEGIN_org
  #+attr_html: :class center :width 300px
  #+caption: Example polyhedron
  #+ATTR_LATEX:  :width 0.45\textwidth :float nil
  [[file:polyhedron.png]]
  #+END_org



#+BEGIN_lemma 
Whenever $x_t$ is unique,  $x^{\alpha}_t \rightarrow_{\alpha \rightarrow 0} x_t$ for all $t \in [0, 1]$
#+END_lemma

#+BEGIN_proof
  See [[papers:Martin1975][Martin1975]]: On the continuity of the maximum in parametric linear programming.
#+END_proof


#+BEGIN_lemma 
If $c_t$ is non constant polynomial, $x_t$ is unique.
#+END_lemma

#+BEGIN_theorem 
$x^{\alpha}_t \rightarrow x_t$ when $\alpha \rightarrow 0$ in $L_1(0, 1)$
#+END_theorem

  
* Density of continuous functions in the space of admissible functions

  Instead of approximating directly the function $x(t)$, we start by approximating $x^{\alpha}(t)$ for some $\alpha$ small enough, and we conclude by continuity of $\alpha \rightarrow x^{\alpha}$.


** Approximating $x^{\alpha}$
  Let:
  - $\mathcal F_{\alpha} = \{f: [0, 1] \rightarrow \mathbb R^n,  f(t) \in \mathcal P_{\alpha} \}$, e.g the space of admissible functions.
  - $\mathcal C_{\alpha} = \mathcal F_{\alpha} \cap C_0$, e.g the space of admissible continuous functions.


  *For a fixed solution of the problem ($Pb_{\alpha}$) $x^{\alpha} \in \mathcal F_{\alpha}$ , let's prove that there exist $g \in \mathcal C_{0}$ as close as we want to it in the $L_1$ norm.*


  We start by approximating the solution $x^{\alpha}$ rather than $x$ directly. We conclude later by continuity of $\alpha \rightarrow x^{\alpha}$.

  

  To do that, fix $\varepsilon > 0$.

#+BEGIN_lemma
If $c(t)$ is polynomial then the set $J$ of discontinuities of $x^{\alpha}$ is finite
#+END_lemma
    
#+BEGIN_proof
Indeed, $x^{\alpha}$ is discontinuous at $t \in J$ only if $c(t)$ is orthogonal to one of the faces of the polyhedron. The set $J$ is thus contained in the roots of the univariate polynomial $t \rightarrow \prod_{i=1\ldots d} \langle c(t), A_i \rangle$.
#+END_proof    

#+BEGIN_theorem
  There exist $g \in \mathcal C_{\alpha}$  such that $\lonenorm{g - x^{\alpha}} \le \varepsilon$.
#+END_theorem

#+BEGIN_proof  
Let's first construct such function $g$.

We construct $g$ by interpolating between different levels of the piece wise constant function $x$ component wise. More specifically, for $i = 1 \ldots n$, let $\beta > 0$ be smaller than half the minimal distance between two discontinuity points.
  
Define $g$ as follow:
- $g(t) = \frac{t - (t_0 - \beta)}{2\beta}(x(t_0^+) - x(t_0^-)) + x(t_0^-)$ if $|t - t_0| \le \beta$ for some $t_0 \in J$
- $g(t) = x(t)$ otherwise.


For all $t \in [0, 1]$, $g(t)$ is a convex combination of $x(t)$ and $0$, both of them in the convex set $\mathcal P$, $g$ is furthermore continuous, so $g \in \mathcal C$.


Let's now prove that $g$ is close enough to $x^{\alpha}$:

$\lonenorm{g - x^{\alpha}} = \sum_{t_0 \in J} \int_{t_0 - \beta}^{t_0 + \beta} \onenorm{g - x^{\alpha}} \le \beta \sum_{t_0 \in J} \onenorm{\Delta x(t_0)}$
Take $\beta = \frac{\varepsilon}{ \sum_{t_0 \in J} \onenorm{\Delta x(t_0)}}$ to conclude.

#+END_proof  
  


#+BEGIN_SRC python :session *PYTHON* :results file :exports results  :wrap (add-caption-and-center "Example of a component of $g$")
  import matplotlib.pyplot as plt
  plt.rcdefaults()

  import numpy as np
  import seaborn

  fig, ax = plt.subplots(figsize=(5, 3))
  x = [1, 2.8, 3.2, 5]
  y = [0, 0, 1, 1]
  plt.plot(x, y, '--')

  x = [1, 3, 3, 5]
  y = [0, 0, 1, 1]
  plt.plot(x, y)




  arrow = mpatches.Arrow(2.8, 1.01, 0.4, 0, width=.1)
  ax.add_patch(arrow)



  label((3, 1.2), "$2\\beta$")
  label((3, -0.2), "$t_0$")
  label((2, 0.1), "$x({t_0}^-)$")
  label((4, 1.1), "$x({t_0}^+)$")

  plt.ylim(-0.5, 1.5)
  plt.tight_layout()
  frame1 = plt.gca()
  frame1.axes.get_xaxis().set_visible(False)
  frame1.axes.get_yaxis().set_visible(False)
  

  filename='functionf.png'
  plt.savefig(filename)
  filename
  #+END_SRC
  
  #+RESULTS:
  #+BEGIN_org
  #+attr_html: :class center :width 300px
  #+caption: Example of a component of $g$
  #+ATTR_LATEX:  :width 0.45\textwidth :float nil
  [[file:functionf.png]]
  #+END_org


** Approximation using polynomial

#+BEGIN_theorem
There exist a polynomial $P$ that approximates $x^{\alpha}$ in $L_1$ that stays in $\mathcal P$:
$\lonenorm{x^{\alpha} - P} \le \frac{\alpha}{\inftynorm{A}} + \varepsilon$
#+END_theorem

#+BEGIN_proof
- Using the lemma, let $Q$ be a polynomial close enough to $g$: $\inftynorm{g - Q} \le \frac{\alpha}{n\inftynorm{A}}$
- That implies that for all $t \in [0, 1]$ and $i = 1\ldots n$: $A_i^TQ(t) = \sum_{j=1}^n A_{ij} Q_j(t) \le \sum_{j=1}^n A_{ij} g_j(t) + \alpha \sum_{j=1}^n |A_{ij}| \le b_i$
- $\lonenorm{x^{\alpha} - P} \le \lonenorm{x^{\alpha} - g} + \lonenorm{x^{\alpha} - P} \le  \frac{\alpha}{\inftynorm{A}} + \varepsilon$
#+END_proof  
  
  
** Back to $x$, use continuity  
  Now fix $\varepsilon' > 0$, and pick $\alpha$ and $\varepsilon$ small enough so that:
  - $\lonenorm{x^{\alpha} - x} \le \varepsilon'$
  - $\frac{\alpha}{\inftynorm{A}} + \varepsilon \le \varepsilon'$


  As a result, we have that
  $$\lonenorm{P - x} \le \lonenorm{P - x^{\alpha}} + \lonenorm{x^{\alpha} - x} \le 2 \varepsilon'$$

  Which concludes the proof.


* Convergence of the solution when $n \rightarrow \infty$


#+BEGIN_theorem
Let $\varepsilon > 0$, if $P^{(n)}$ is the solution to $(Pbn)$, then $\int_0^1 \langle c, P^{(n)} \rangle \rightarrow_n \int_0^1 \langle c, x \rangle$
#+END_theorem

#+BEGIN_proof
Let $Q$ the polynomial approximating $x$ from the previous lemma, and note $n$ its degree
Let $P^{(n)}$ the solution to $(Pbn)$, then:



\begin{align*}
\int_0^1 \langle c,  P^{(n)}\rangle - \int_0^1 \langle c, x\rangle
&\le \int_0^1 \langle c,  Q\rangle - \int_0^1 \langle c, x\rangle  & \text{(because $P^{(n)}$ is optimal)}
\\&\le \inftynorm{c} \int_0^1  \onenorm{x_t - Q(t)}dt 
\\&\le \inftynorm{c} \varepsilon 
\end{align*}

Which proves that as $n \rightarrow \infty$, we converge to the correct optimal value.
#+END_proof

  
  

