% Created 2016-03-10 Thu 18:40
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage{minted}
\usepackage[margin=0.5in]{geometry}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\newtheorem{thm}{Lemma}
\newcommand{\Problem}[1]{\subsection*{Problem #1}}
\newcommand{\Q}[1]{\subsubsection*{Q.#1}}
\newcommand{\union}[1]{\underset{#1}{\cup} }
\newcommand{\bigunion}[1]{\underset{#1}{\bigcup} \, }
\newcommand{\inter}[1]{\underset{#1}{\cap} }
\newcommand{\biginter}[1]{\underset{#1}{\bigcap} }
\newcommand{\minimize}[3]{\optimize{#1}{#2}{#3}{min}}
\newcommand{\maximize}[3]{\optimize{#1}{#2}{#3}{max}}
\DeclareMathOperator{\cov}{cov}
\DeclareMathOperator{\var}{var}
\author{Bachir El khadir}
\date{\textit{<2016-02-23 Tue>}}
\title{Problem set 3, ORF523}
\hypersetup{
 pdfauthor={Bachir El khadir},
 pdftitle={Problem set 3, ORF523},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 24.5.1 (Org mode )}, 
 pdflang={English}}
\begin{document}

\maketitle
\begin{HTML}

\label{orgspecialblock1}

\end{HTML}

\section{Problem 1}
\label{sec:orgheadline1}
\begin{enumerate}
\item The treatment planning problem minimizes the penalty \(E = \sum_{i \not \in \mathcal T} (a_i b - D^{\text{other}})^+\), where \(a_i\) is the i-th row of \(A\),  under the constraints: \(\forall i \in \mathcal T\; a_i b \ge D^{\text{target}}\), \(0 \le b \le B_{\max}\)
\begin{itemize}
\item For all \(i \not \in \mathcal T\), \(b \rightarrow a_ib - D^{\text{other}}\) is linear, \((.)+\) is convex, and so is its composition with a linear function. As a sum of such functions \(E\) is a convex.
\item The constraints are all linear inequalities of \(b\).
\end{itemize}
So the problem is convex.
\item Without loss of generality, we can
\end{enumerate}

\begin{minted}[frame=lines,linenos=true]{matlab}
treatment_planning_data;
cvx_begin quiet
variable b(n)
variable dtumor(mtumor)
variable dother(mother)
variable E;
minimize sum(max(dother - Dother, 0))
subject to
dother == Aother * b
dtumor == Atumor * b
dtumor >= Dtarget
0 <= b <= Bmax
cvx_end
ans = cvx_optval
\end{minted}



\begin{minted}[frame=lines,linenos=true]{matlab}
fig1 = figure;
hist(dother, 20);
fig2 = figure;
hist(dtumor, 20);
saveas(fig1, 'dother.png');
saveas(fig2, 'dtumor.png');
\end{minted}



\begin{center}
\includegraphics[width=0.38\textwidth]{./dother.png}
\captionof{figure}{d other}
\end{center}

\begin{center}
\includegraphics[width=0.38\textwidth]{./dtumor.png}
\captionof{figure}{d tumor}
\end{center}

As expected, the dose delivred to the non-target voxels is concentrated around 0.2 (very close to the value we want for \(d^{other}\)), while the dose delivred to the target voxels is concentrated around 1.


\section{Problem 2}
\label{sec:orgheadline2}
\begin{enumerate}
\item Let's first prove that \(dom(M_c)\) is convex.

Let \(\alpha \in (0, 1)\), \(x, y \in dom(M_c)\), and let \(a \ge M_c(x), b \ge M_c(y)\), such that \(\frac xa, \frac yb \in dom(M_c)\). 
Let \(\lambda = \frac1 { 1  + \frac ba \frac{1-\alpha}\alpha}\) and \(t = \alpha a + (1-\alpha) b\), it is clear that:
\begin{itemize}
\item \(\lambda \in (0, 1)\), \(t > 0\).
\item \(\frac{\alpha x + (1-\alpha) y}t = \lambda \frac xa + (1-\lambda) \frac yb \in C\) because \(C\) is convex.
\end{itemize}
\end{enumerate}
So \(\alpha x + (1-\alpha)y \in dom(C)\), which proves that \(dom(C)\) is convex.

Let's now prove that \(M_c\) is convex. We have just proved that \(M_c(\alpha x + (1-\alpha)y) \le t = \alpha a + (1-\alpha) b\), and this for all \(a \ge M_c(x), b \ge M_c(y)\), such that \(\frac xa, \frac yb \in dom(M_c)\). If we take the \(\inf\) we respect to \(a\) and \(b\) we find that
$$M_c(\alpha x + (1-\alpha)y) \le \alpha M_c(x) + (1-\alpha) M_c(y)$$
and the function \(M_c\) is convex.

\begin{enumerate}
\item 
\end{enumerate}

\begin{thm}
\(\forall a > 0 \; M_c(a x) = \inf \{ t > 0 | \frac {ax}t \in C\} =  \inf \{ t > 0 | \frac {x}{t/a} \in C\} = a  \inf \{ \frac{t}a > 0 | \frac {x}{t/a} \in C\} = a M_c(a)\)
\end{thm}


\begin{thm}
\(M_c(-x) = \inf \{ t > 0 | \frac {-x}t \in C\} = \inf \{ t > 0 | \frac {x}t \in C\} = M_C(x)\) because \(x \in C \iff -x \in C\)
\end{thm}

\(M_C\) is a norm, indeed:

\begin{itemize}
\item \(dom(M_C) = \mathbb R^n\): \(C\) has non empty interior, so it contains a ball \(B(x, \varepsilon)\), by symmetry it contains also \(B(-x, \varepsilon)\). Let's prove that it contain \(B(0, \varepsilon)\), for this, consider \(y \in \mathbb R^d\) whose norm is smaller than \(\varepsilon\), then \(y = \frac12 \underbrace{(x + y)}_{\in B(x, \varepsilon)} + \frac12 \underbrace{(-x + y)}_{\in B(-x, \varepsilon)} \in C\). Now for \(z \in \mathbb{R}^d\), \(\varepsilon\frac{z}{2||z||} \in B(0, \varepsilon) \subseteq C\), and therefore \(z \in dom(M_C)\)
\item Triangular inequlity:
\begin{align*}
M_C(x+y) &= 2 M_C(\frac12 x + \frac12 y)  &\text{(Lemma 1)}
\\&\le 2 (\frac12 M_C(x) + \frac12 M_C(y)) &\text{(Convexity)}
\\&= M_C(x) + M_C(y)
\end{align*}
\item Zero vector: Let \(x\) be such that \(M_C(x) = 0\), this implies that there exist a sequence \(t_n \downarrow 0\) such that \(\frac{x}{t_n} \in C\). \(C\) being compact, there exist a subsequence \(\frac x{t_{n_k}}\) that converges to \(x_0 \in C\). If \(x \ne 0\) then \(||x_0|| = ||x|| \lim \frac1{t_{n_k}} = \infty\) would be a contradiction, so \(x = 0\).
\item Absolute homogeneity: Let \(x \in C\), \(a \in \mathbb{R}\) and let's prove \(M_C(ax) = |a|M_C(x)\).

\begin{itemize}
\item For the case \(a = 0\) look at previous point
\item For \(a > 0\) look at lemma 1.
\item For \(a < 0\), \(M_C(ax) = M_C( (-a) -x) \underbrace{=}_{lemma 1} (-a) M_C(-x) = |a| M_C(-x) \underbrace{=}_{\text{lemma 2}} |a| M_C(x)\).
\end{itemize}
\end{itemize}


Let's prove that the unit ball \(B\) is equal to \(C\): 
\begin{itemize}
\item Let \(x\) such that \(M_C(x) \le 1\), and let \(t_n\) a non-increasing sequence to \(M_C(x)\) such that \(\frac{x}{t_n} \in C\), by compactness of \(C\) the limit \(\frac{x}{M_C(x)} \in C\). By convexity of \(C\), \(x = M_C(x) \frac{x}{M_C(x)} + (1-M_C(x)) 0 \in C\).
\item if \(x \in C\), then \(M_C(x) \le 1\) because \(\frac x1 \in C\)
\end{itemize}
\begin{enumerate}
\item convex \(\implies\) quasi convex. (Seen in class)

Let's now consider that \(p(x)\) is even degree quasi convex and homogeneous. Then:
\begin{itemize}
\item \(\forall t > 0\), \(p(t x) = t^d p(x)\)
\item \(p(x) \ge 0\), because otherwise if there exist \(x\) such that \(p(-x) = p(x) < 0\), then \(p(0) = p(\frac12 x - \frac12 x)\) should be negative because \(\{u, p(u) \le p(x)\}\) is convexe because \(p(x)\) is quasi convex.
\item \(Q := \{ x, p(x) \le 1 \}\) is convex.
\end{itemize}
\(p(x) = \inf\{ t > 0 | \frac{p(x)}{t} \le 1\} = \inf\{ t > 0 | p(\frac{x}{t^{\frac1d}}) \le 1\} = \inf\{ t > 0 | \frac{x}{t^{\frac1d}} \in Q\} = \inf\{ t > 0 | \frac{x}{t} \in Q\}^d = M_Q(x)^d\)
so \(p(x)\) is convex as a composition of the non negative convex function \(M_Q\) and the non-decreasing convex function on \([0, \infty)\) \(t \rightarrow t^d\)
\end{enumerate}

\section{Problem 3}
\label{sec:orgheadline3}
Let \(A\) be a double sotchastic matrix. Let \(G = (U_1\times U_2, V, E)\) be the associated bipartite graph as follow:
\begin{itemize}
\item \(U_1 = U_2 = \{1, \ldots, n\}\) the set of nodes.
\item \(E = \{e_{ij} = 1_{a_{ij} > 0}\}\) the set of edges where \(e_{ij} = 1\) if the nodes \(i \in U_1\) and \(j \in U_2\) are connected.
\item Let \(B\) be the associated incidence matrix.
\end{itemize}
The feasible set to the relaxed maximum matching program ( program (3) in note 6) is a bounded polyhedral, so the optimal value is attained in one of the vertices. Since the incidence matrix is TUM (seen in class), there exist an integral solution that we represent by \(P \in \mathbb R^{n^2}\) where \(P_{ij} = 1\) if and only if the two nodes \(i\) and \(j\) are connected in the solution.

To see that \(P\) is in fact a perfect matching, consider the feasible solution \(A'\) that gives to each edge \(e_{ij}\) the value \(a_{ij}\):

\begin{itemize}
\item It is feasible by construction of the graph \(G\)
\item The value of this solution is exactly \(n\) because the matrix is doubly stochastic.
\item By maximality of \(P\), the sum of its entries should also sum up to at least \(n\). Since each column and row of \(P\) contains at most one \(1\), it should actually contain exactly one (otherwise theeir sum would be strictly smaller than \(n\)).  \(\implies P\) is a permutation.
\end{itemize}


let \(\alpha \le 1\) be maximal real number verifying \(A_1 := A - \alpha P \ge 0\). It is easy to see that:
\begin{itemize}
\item \(\alpha \ne 0\) because by construction of the graph \(G\), each non zero entry \(P_{ij}\) of \(P\) corresponds to a non zero entry \(a_{ij}\) in \(A\).
\item If \(\alpha = 1\) we are done. We assume that \(\alpha > 0\)
\item \(\frac{A_1}{1-\alpha}\) is doubly stochastic.
\item \(\frac{A_1}{1-\alpha}\) contains at least one additional zero than \(A\).
\end{itemize}

By induction on the number of zeros on the matrix, apply the same technique recuresvely to \(A_1\) until one of the \$\(\alpha\)\$s is 1 to obtain the convex decomposition \(\frac{A_1}{1-\alpha} = \sum_{i=1}^d \alpha_i P_i\) where all the \(P_i\) are permutations, and conclude by noticing that:
$$A = \sum_{i=1}^d \frac{\alpha_i}{1-\alpha} P_i + \alpha P$$


\section{Problem 4}
\label{sec:orgheadline4}

\textbf{The if part:}

\begin{thm}
Let's assume that \(A\) is TUM. Then  \(A_1 = (A \; ; \; -I_n )\) where \(I_n\) is the \(n \times n\) identity matrix is also TUM.
\end{thm}
\begin{proof}
Indeed:
\begin{itemize}
\item take a submatrix of \(A_1\), if doesn't contain a cloumn coming from \(-I_n\), then we are done, if it does:
\item let \(m\) denote the number of such columns. Develop the determinant of the submatrix with respect to one of them. We see immediately that it is equal to the determinant of a submatrix of \(A_1\) containing \(m-1\) columns coming from \(-I_n\)
\item We conclude by induction on the dimension of \(A_1\)
\end{itemize}
\end{proof}

Now we can write:
\[\{ x | x \ge 0 Ax \le b\} = \{ x |  (A \; ; \; -I ) x \le \begin{pmatrix}b \\ 0\end{pmatrix}  \}\]

We proved in class that the vertices of the RHS are integrale if \(b\) is integrale, and vertices (or extreme points) don't depend on the actual description of the polyhedron.

\textbf{The only if part:}

Let's now assume that \(A\) is not TUM, and let's prove that there exist of \(b\) for which the polyhedron is not integrale.

First, let's prove two lemmas:
\begin{thm}
\(A\) not TUM \(\implies\) there exist a submatrix of size \(n \times n\) that of \[ C := \begin{pmatrix}A \\ -I_n\end{pmatrix} \]  has determinant not in \(\{0, 1, -1\}\) 
\end{thm}

\begin{proof}
Let's assume \(A\) is not \(TUM\), then there exist \(A_1\) a submatrix of B that has determinant not in \(\{0, 1, -1\}\).

Notation:
\begin{itemize}
\item Let's call \(p\) the size of \(A_1\). If \(p = n\) we are done, so let's assume \(p < n\).
\item Let's call \(c_1 < \ldots c_p\), (resp \(r_1 < \ldots r_p\)) the indices corresponding to the columns (resp rows) used to construct \(A_1\).
\((A_1)_{jk} = C_{r_j, c_k}\)
\item \(c_{p+1} < \ldots < c_n\) are the indices the column in \(C\) not used in \(A_1\)
\item \(r_{p+j} = c_{p+j}\) for \(j = 1 \ldots (n-p)\), e.g.  the indices of rows in \(-I_n\) that have \(1\) in the \(c_{p+j}\) place:
\(C_{r_{p+j}, c_{p+k}} = -\delta_{jk}\)
\end{itemize}

Construct the submatrix \(A_2\) of \(C\) of size \(n\) by doing taking the all the columns \(c_1, \ldots c_n\) from \(C\) and the rows \(r_1 \ldots r_n\), if we rearrange the order of the columns in \(A_2\) we get this:

\[    \begin{pmatrix}    \begin{array}{c}r_1 \\ \vdots\\ r_p \end{array} \left\{\right. &  \underbrace{A_1}_{c_1, \ldots c_p} & * \\   \begin{array}{c}r_{p+1} \\ \vdots\\ r_n \end{array} \left\{\right. &  0 & \underbrace{-I_{n-p}}_{c_{p+1}, \ldots c_n} \\    \end{pmatrix}    \]



By developping the determinant of \(A_2\) with respect to the last rows we can see it is equal to \((-1)^{n-p}\det(A_1)\), so different from \(1, -1, 0\).
We have just construct a matrix whose determinant is not in  \(\{0, 1, -1\}\) and is bigger than \(\tilde A\). Contradiction.
\end{proof}


\begin{thm}
\(det(M) \not \in \{1, 0, -1\} \implies (\exists t \in \mathbb R^n)\; M^{-1}t \text{ integrale with } t \text{ not integrale }\)
\end{thm}

\begin{proof}
Assume that \(det(M) \not \in \{1, 0, -1\}\).
Then the \(det(M^{-1}) = \frac1{ det(M) } \not \in \mathbb{Z}\), then there exist an entry \(a_{ij}\) in \(M^{-1}\) that is not integer.
Let \(u\) be the vector with zeros except  the \(i^{th}\) entry which is equal to \(1\), then \(M^{-1}u\) is not integer because \(M^{-1}u = m_{ij}\), but \(M \underbrace{(M^{-1} u)}_{t}\) is integer.
\end{proof}

Back to the proof.


By using the first Lemma, there exist a submatrix \(\tilde C\) of \(C\) of size \(n \times n\) such that \(\det(\tilde C) \not \in \{0, 1, -1\}\). Let's call \(r_1, \ldots r_n\) the indices of the rows used in that construction.

Using the second lemma, there exist an non integrale vector \(t\) such that \(\tilde C t\) is integrale, so \(Ct\) contains at least \(n\) integrale componenets. 

Let \(\tilde b = \lceil Ct \rceil\), where \(\lceil.\rceil\) is the component wise ceiling to nearest integer.
It is clear that: \(Ct \le \tilde b\) with at least \(n\) tight constraints.
Let's write \(\begin{pmatrix} b_1 \\b_2\end{pmatrix} = \tilde b\) where \(b_1 \in \mathbb R^n\),  \(b_2 \in \mathbb R^m\).
We have just proved that:

\(\underbrace{\{ x \in \mathbb R^{n} |  Cx \le \tilde b\}}_{P} = \{ x \in \mathbb R^{n} | x \ge b_2, \; Ax \le  b_1\}\) has a non integrale vertex.

The polyhedron \(\underbrace{\{ x | x \ge 0 Ax \le (b_1 - Ab_2)\}}_{P_2}\) is obtained by translating \(P\) with the images of the translation whose vector is \(b_2\), so it vertices are the image of the vertices of \(P\) by the translation \(b_2\). In particular, Since \(t - b_2\) is a vertex of \(P_2\).

Now we have that:
\begin{itemize}
\item \(b_1 - Ab_2\) is integrale because \(b_1, b_2, A\) are integrale
\item \(t - b_2\) is not integrale because \(t\) is not integrale and \(b_2\) is integrale
\item \(\implies P_2\) has  integrale vertex.
\end{itemize}

Which ends the proof.
\end{document}