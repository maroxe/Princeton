\documentclass[12pt]{article}

% packages
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{enumitem}
\usepackage{graphicx}

\usepackage[numbered,framed]{matlab-prettifier}

\newenvironment{question}[1]
{\Q{#1}}{}

\newenvironment{problem}[1]
{\section*{Problem #1}}{}

\newcommand{\Problem}[1]{\subsection*{Problem #1}}
\newcommand{\Q}[1]{\subsubsection*{Q.#1}}
\newcommand{\union}[1]{\underset{#1}{\cup} }
\newcommand{\bigunion}[1]{\underset{#1}{\bigcup} \, }
\newcommand{\inter}[1]{\underset{#1}{\cap} }
\newcommand{\biginter}[1]{\underset{#1}{\bigcap} }

\newcommand{\minimize}[3]{\optimize{#1}{#2}{#3}{min}}
\newcommand{\maximize}[3]{\optimize{#1}{#2}{#3}{max}}

\DeclareMathOperator{\cov}{cov}
\DeclareMathOperator{\var}{var}


% parameters
\geometry{hmargin=1.5cm,vmargin=1.5cm}
\title{ORF523 - Problem Set 1}
\author{Bachir EL KHADIR }

\begin{document}
\maketitle



\begin{problem}{1}

  \begin{enumerate}
  \item Let $\lambda$ be an eigen value of $A^TA$ corresponding to an eigen vector $u \ne 0$, then $0 \le ||Au||^2 = u^TA^TAu = \lambda ||u||^2$, therefore $\lambda > 0$.
  \item Let $\lambda$ be an eigen value of $A$ corresponding to an eigen vector $u$, the $A^TAu = A(Au) = \lambda^2 u$, so $\lambda^2$ is an eigen value of $A^TA$. Since $A$ has $n$ eigen values (accounting for multplicity), the eigen values of $A^TA$ are exactly the squares of the eigen values of $A$, and therefore the singular values of $A$ are the absolute values of the eigen values of $A$.

  \item
    $$u_i^Tu_j = u_i^T\frac{A^TAu_j}{\lambda_j} = \frac{u_i^TA^TA}{\lambda_j}u_j$$
    Since $\lambda_i \ne \lambda_j$, $u_i^Tu_j = 0$
  \end{enumerate}

  

  \begin{itemize}
  \item The $L_2$ norm for vectors is unitarly invariant:
    Let $O$ unitary matrix and $X$ a vector, then $||OX||^2  = X^TO^TOX = X^TX = ||X||^2$.
  \item Since $O$ is invertible, the application $S \rightarrow S, X \rightarrow OX$, where $S$ is the $L_2$ sphere, is a bijection. So   $\{ x, ||x||_2 = 1\} = \{ Ox, ||x||_2 = 1\}$
  \item The $L_2$ norm for matrices is unitarly invariant.
    If $A$ a matrix, then $||AO|| = \max_{||x||_2 = 1} ||AOx|| = \max_{||Ox||_2 = 1} ||AOx|| = \max_{||y||_2 = 1} ||Ay|| = ||A||$ and
    $||OA|| = \max_{||x||_2 = 1} ||OAx|| = \max_{||x||_2 = 1} ||Ax|| = ||A||$.
  \item
    Let $B$ be a matrix of rank at most $k$.
    $||A - B|| = ||U(\Sigma - U^TBV)V^T|| = ||\Sigma - U^TBV||$
    Let's do the change of variable $C = U^TBV$, and since $U$ and $V$ are invertible,  that $rank(B) = rank(C)$.

    
    $rank(B)  \le k \Rightarrow null(C) \ge n - k$, therefore $\{ e_1, \ldots, e_{k+1} \} \cap null(C) \ne \{ 0 \}$ (otherwise the dimension of the sum will exceed $n$).
    Let $u = \sum_{i \le k+1} \alpha_i e_i$ in that intersection, and assume wihtout loss of generality that $|u| = \sum_{i \le k+1} \alpha_i^2 = 1$. 

    $|(\Sigma - C)u|^2 = |\sum_{i \le k+1} \alpha_i e_i|^2 = \sum_{i \le k+1} \alpha_i^2 \sigma_i \ge \sigma_{k+1}$, so $|\sigma - C|_2 \ge \sigma_{k+1}$.

    $|\Sigma - \Sigma^{(k)}| = |diag(0, \ldots, \sigma_{k+1}, \ldots)| = \sigma_{k+1}$

    and since $rank(\Sigma^{(k)}) = k$, it is the argmin. Doing the inverse the change of variable $B = UCV^T = U \Sigma^{(k)} V^T$.

    But $U \Sigma^{(k)} V^T = U^{(k)} \Sigma^{(k)} {V^{(k)}}^T$. To prove that we consider the column vectors of $V$: $(v_1, ..., v_n)$, and we have that:
    \[
      U^{(k)} \Sigma^{(k)} {V^{(k)}}^T v_i =
      \left \{
        \begin{array}{cc}
          U^{(k)} (\sigma_i e_i) = \sigma_i u_i &\text{if } i \le k \\
          0 = U \Sigma^{(k)}e_i   &\text{if } i > k \\
        \end{array}
      \right \}
      = U \Sigma^{(k)} V v_i
    \]
    
    Which proves the result.
  \end{itemize}



  \begin{enumerate}
  \item
    50.2409   31.2567   18.0737    9.9583
    \[
      \begin{array}{c|c}
        k & ||A - A_{(k)}||_F \\
        \hline
        25&50.24\\
        50&31.25\\
        100&18.07\\
        200&9.96\\
      \end{array}
    \]

  \item To store $A^{(k)}$ we need only to store $\Sigma^{(k)}$ ($k$ parameters), $U^{(k)}, V^{(k)}$ (each of them has only at most $k$ column not set to zero, so they take $nk + mk$), while $A$ takes $nm$ numbers to store.
    In conclusion, we save ($nm - k(n+m+1)$).
    \begin{itemize}
    \item \includegraphics[scale=.75]{compressed.png}

    \item \includegraphics[scale=.75]{diffnorm.png}


    \item \includegraphics[scale=.75]{totalsavings.png}

      for $k = 200$, the total saving is 975100.
    \end{itemize}
  \item Comparing the original and the compressed image for $k = 200$. You can't tell the difference.
    
    \includegraphics[scale=.75]{compare.png}
  \end{enumerate}


  \subsubsection*{Code}
  \lstinputlisting[style=Matlab-editor]{imageprocessing.m}


\end{problem}
\begin{problem}{2}


  \begin{enumerate}
  \item
    Let $u = x_1 + x_2$, it is easy to verify that
    $f(x_1, x_2) = \underbrace{\frac {u^2}2 - 2u}_{g(u)} + \underbrace{- 2 x_2^2 + 3 x_2 + \frac13 x_2^3}_{h(x_2)} = g(u) + h(x_2)$

    Since this transformation is a diffeomorphisme, it preserves neighbourhoods, and therefore it preserves local minimizers/maximizers.

    A point $(u, x_2)$ is a local maximizer (resp. minimizer) of $g(u) + h(x_2)$ if and only if $u$ is a local maximizer (resp. minimizer) of $g$ and $x_2$ is local maximizer (resp. minimizer) of $h$.

    \begin{itemize}
    \item $g(u) = \frac12 (u-2)^2 - 2$ has one local(and global) minimum
      $u = 2$
    \item $h'(x_2) = x_2^2 - 4x_2 + 3 = (x_2 - 1)(x_2 - 3)$,
      $h''(x_2) = 2x_2 - 4$ 
    \end{itemize}
    The candidates are $x_2 = 1$ and $x_2 = 3$. Since $h''(1) = -2 < 0, h''(3) = 2 > 0$, $1$ is local maximum and $3$ is a local minimum.
    $f$ canot have a local maximum because $g$ doesn't have one.
    
    In conclusion, $(u, x_2) = (2, 3)$ is the only local optimizer (it is a local min) of $g(u) + h(x_2)$, and  $(x_1 = -5, x_2 = 3)$ is the only local optimizer (minimum) of $f$.

  \item
    By Taylor expansion, since $f$ is a polynomial of order 2: $f(x) - f(\bar x) = \nabla f(\bar x)(x - \bar x) + \frac12 (x-\bar x)^T \nabla^2 f(x - \bar x) (x-\bar x)$
    \begin{enumerate}
    \item[a)]
      \begin{enumerate}
      \item[($\Rightarrow$)]
        Let $\bar x$ be a local min, then $\nabla f(\bar x) = 0$.
        If $\nabla^2 f$ is not positive semi-definite, let $d \in \mathbb{R}^n d^T\nabla f(\bar x) =: -\lambda < 0$, therefore $f(x + \alpha d) - f(x) = - \alpha^2 \lambda < 0$, and for any neighbourhood of $\bar x$, there exist $\alpha$ such that $\bar x + \alpha d$ is in that neighbourhood, and we have a contradiction.
      \item[($\Leftarrow$)]
        In this case: $f(x) - f(\bar x) = \frac12 (x-\bar x) \nabla^2 f(x - \bar x) \ge 0$, which proves that $\bar x$ is local min.
      \end{enumerate}

    \item[b)]
      \begin{enumerate}
      \item[($\Rightarrow$)]
        In this case: $f(x) - f(\bar x) = \frac12 (x-\bar x) \nabla^2 f(x - \bar x) > 0$, which proves that $\bar x$ is strict local min.
      \item[($\Leftarrow$)]
        In this case: $f(x) - f(\bar x) = \frac12 (x-\bar x) \nabla^2 f(x - \bar x) > 0$, which proves that $\bar x$ is strict local min.
      \end{enumerate}
    \end{enumerate}

    Counterexamples:
    $f: \mathbb R \rightarrow \mathbb R, x \rightarrow x^3$, $f'(0) = 0, f''(0) = 0$, but $0$ is not a local min.
    $f: \mathbb R \rightarrow \mathbb R, x \rightarrow x^4$, $f'(0) = 0, f''(0) = 0$, but $0$ is a strict local min.
  \item using the chain rule: $g'(\alpha) = \frac{d}{||d||} \nabla f(x + \alpha \frac{d}{||d||})$, $g'(0) = \frac{d}{||d||}\nabla f(x)$.
    

    Using Cauchy-Shwarz, $|\frac{d}{||d||}\nabla f(x)| \le ||\nabla f(x)||$, so
    $\frac{-\nabla f(x)}{||\nabla f(x)||}\nabla f(x) \le \frac{d}{||d||}\nabla f(x) \le \frac{\nabla f(x)}{||\nabla f(x)||}\nabla f(x)$
    
  \end{enumerate}

\end{problem}
\begin{problem}{3}

  $Q > 0$, so it admist an eigenvalue decomposition and all the eigen values are positive, let $Q = U\Sigma U^T$ be that decomposition, with $\Sigma = diag(\sigma_1, \ldots, \sigma_n)$, and Let $\sqrt{\Sigma} =diag(\sqrt{\sigma_1}, \ldots, \sqrt{\sigma_n})$, then $Q = \underbrace{U\sqrt{\Sigma}U^T}_{\sqrt Q}U\sqrt{\Sigma}U^T = \sqrt{Q}^2$

  $f(x) = \sqrt{ x^T\sqrt{Q}\sqrt{Q}x} = \sqrt{ ||\sqrt Q x||^2} = ||\sqrt Q x||$

  \begin{enumerate}
  \item f is a norm because:

    \begin{itemize}
    \item $$f(\lambda x) = \sqrt{(\lambda x)^TQ(\lambda x)} = \sqrt{\lambda^2} f(x) = |\lambda| f(x)$$
    \item
      $$f(x + y) = ||\sqrt{Q}x + \sqrt{Q}y|| \le ||\sqrt{Q}x|| + ||\sqrt{Q}y|| \le f(x)+ f(y)$$
    \item $$f(x) = 0 \iff \sqrt{Q}x = 0 \iff x = 0$$
    \end{itemize}
  \item

    By Riesz Representation theorem, we indentify a vector $x$ with the linear form $y \rightarrow x^Ty$.
    Let $g$ be the dual norm of $f$, then
    \begin{align*}
      g(x) &= \sup_{y \ne 0} \frac{x^Ty}{f(y)}
      \\&= \sup_{u \ne 0} \frac{x^T\sqrt{Q}^{-1}u}{||u||} &(y \rightarrow u=\sqrt{Q}y \text{ is a bijection})
      \\&= \sup_{u \ne 0} x^T\sqrt{Q}^{-1}\frac{u}{||u||}
      \\&= x^T\sqrt{Q}^{-1}\frac{(\sqrt{Q}^{-1}x)}{||\sqrt{Q}^{-1}x||} &\text{(Cauchy shwarz, like in Problem 2)}
      \\&= \frac{x^TQ^{-1}x}{\sqrt{x^TQ^{-1}x}}
      \\ &= \sqrt{x^TQx^{-1}}
    \end{align*}

  \item
    $A^TA \ge 0$, Let $U\Sigma U^T$ be an eigen value decomposition where $\Sigma = diag(\sigma_1, \ldots, \sigma_n)$, and $\sigma_1 \ge \ldots \ge \sigma_n \ge 0$.
    
    \begin{align*}
      ||A||_2 &= \sup_{||x||=1} x^T(A^TA)x
      \\&= \sup_{||x||=1} ||\sqrt{A^TA}x||
      \\&= ||\sqrt{A^TA}||_2
      \\&= ||\Sigma||_2 \\&= \sup_{||x||=1} x^T(\Sigma)x \\&= \sup_{||x||=1} \sum_i x_i^2 \sigma_i \le \sum_{i} x_i^2 \sigma_1 \\&= \sigma_1 \\&= ||\Sigma e_1||
    \end{align*}

    So $||A||_2 = \sigma_1 = \sqrt{\lambda_{\text{max}}(A^TA)}$

  \end{enumerate}
\end{problem}

\end{document}
























