# -*- mode: org; org-confirm-babel-evaluate: nil; org-speed-commands-user: nil; org-use-speed-commands: t; -*-

#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="../../css/special-block.css" />
#+HTML_HEAD: <link href="http://thomasf.github.io/solarized-css/solarized-dark.min.css" rel="stylesheet"></link>
#+HTML_HEAD: <script type="text/javascript" src="http://code.jquery.com/jquery-latest.min.js"></script>
#+HTML_HEAD: <script src="http://127.0.0.1:60000/autoreload.js"></script>

#+OPTIONS: ':nil *:t -:t ::t <:t H:3 \n:nil ^:t arch:headline
#+OPTIONS: author:t broken-links:nil c:nil creator:nil
#+OPTIONS: d:(not "LOGBOOK") date:t e:t email:nil f:t inline:t num:t
#+OPTIONS: p:nil pri:nil prop:nil stat:t tags:t tasks:t tex:t
#+OPTIONS: timestamp:t title:t toc:t todo:t |:t
#+OPTIONS: toc:nil h:nil

#+LANGUAGE: en
#+SELECT_TAGS: export
#+EXCLUDE_TAGS: noexport
#+CREATOR: Emacs 24.5.1 (Org mode )


#+LATEX_HEADER: \usepackage[margin=0.5in]{geometry}

#+LATEX_HEADER:  \usepackage{amsmath}
#+LATEX_HEADER: \usepackage{amsfonts}
#+LATEX_HEADER: \usepackage{amsthm}

#+LATEX_HEADER: \newtheorem{thm}{Lemma}


#+LATEX_HEADER: \newcommand{\Problem}[1]{\subsection*{Problem #1}}
#+LATEX_HEADER: \newcommand{\Q}[1]{\subsubsection*{Q.#1}}
#+LATEX_HEADER: \newcommand{\union}[1]{\underset{#1}{\cup} }
#+LATEX_HEADER: \newcommand{\bigunion}[1]{\underset{#1}{\bigcup} \, }
#+LATEX_HEADER: \newcommand{\inter}[1]{\underset{#1}{\cap} }
#+LATEX_HEADER: \newcommand{\biginter}[1]{\underset{#1}{\bigcap} }
#+LATEX_HEADER: \newcommand{\minimize}[3]{\optimize{#1}{#2}{#3}{min}}
#+LATEX_HEADER: \newcommand{\maximize}[3]{\optimize{#1}{#2}{#3}{max}}
#+LATEX_HEADER: \DeclareMathOperator{\cov}{cov}
#+LATEX_HEADER: \DeclareMathOperator{\var}{var}


#+TITLE: Problem set 3, ORF523
#+DATE: <2016-02-23 Tue>
#+AUTHOR: Bachir El khadir

#+name: Watch changes
#+BEGIN_HTML 
@@html:<script>@@
@@html:AutoReload.Watch('localhost:60000');@@
@@html:</script>@@
#+END_HTML

#+BEGIN_SRC emacs-lisp :exports none
(defun add-caption-header-and-center (caption header )
  (concat (format "org\n#+attr_html: :class center\n#+caption: %s\n%s" caption header)))

  (defun add-caption-and-center (caption)
    (concat (format "org\n#+attr_html: :class center\n#+caption: %s" caption)))

#+END_SRC

#+RESULTS:
: add-caption-and-center



* Problem 1
  1. The treatment planning problem minimizes the penalty $E = \sum_{i \not \in \mathcal T} (a_i b - D^{\text{other}})^+$, where $a_i$ is the i-th row of $A$,  under the constraints: $\forall i \in \mathcal T\; a_i b \ge D^{\text{target}}$, $0 \le b \le B_{\max}$
     - For all $i \not \in \mathcal T$, $b \rightarrow a_ib - D^{\text{other}}$ is linear, $(.)+$ is convex, and so is its composition with a linear function. As a sum of such functions $E$ is a convex.
     - The constraints are all linear inequalities of $b$.
     So the problem is convex.
  2. Without loss of generality, we can

#+name: solve     
#+BEGIN_SRC matlab :session *MATLAB* :cache yes
       treatment_planning_data;
       cvx_begin quiet
       variable b(n)
       variable dtumor(mtumor)
       variable dother(mother)
       variable E;
       minimize sum(max(dother - Dother, 0))
       subject to
       dother == Aother * b
       dtumor == Atumor * b
       dtumor >= Dtarget
       0 <= b <= Bmax
       cvx_end
       ans = cvx_optval
#+END_SRC

#+RESULTS[87481868201bebdffbbac56098026f826fb4012b]: solve
: 1.3882



#+name: plot
#+BEGIN_SRC matlab :session *MATLAB* :cache yes
fig1 = figure;
hist(dother, 20);
fig2 = figure;
hist(dtumor, 20);
saveas(fig1, 'dother.png');
saveas(fig2, 'dtumor.png');
#+END_SRC

#+RESULTS[c3cb7f36b77451c4f1fd11e10f11a653c7264593]: plot
: org_babel_eoe



#+CAPTION: d other
#+ATTR_LATEX: :float nil
#+ATTR_LATEX: :width 0.38\textwidth
[[./dother.png]]

#+CAPTION: d tumor
#+ATTR_LATEX: :float nil
#+ATTR_LATEX: :width 0.38\textwidth
[[./dtumor.png]]

As expected, the dose delivred to the non-target voxels is concentrated around 0.2 (very close to the value we want for $d^{other}$), while the dose delivred to the target voxels is concentrated around 1.


* Problem 2
1. Let's first prove that $dom(M_c)$ is convex.
   
   Let $\alpha \in (0, 1)$, $x, y \in dom(M_c)$, and let $a \ge M_c(x), b \ge M_c(y)$, such that $\frac xa, \frac yb \in dom(M_c)$. 
   Let $\lambda = \frac1 { 1  + \frac ba \frac{1-\alpha}\alpha}$ and $t = \alpha a + (1-\alpha) b$, it is clear that:
   - $\lambda \in (0, 1)$, $t > 0$.
   - $\frac{\alpha x + (1-\alpha) y}t = \lambda \frac xa + (1-\lambda) \frac yb \in C$ because $C$ is convex.
So $\alpha x + (1-\alpha)y \in dom(C)$, which proves that $dom(C)$ is convex.

Let's now prove that $M_c$ is convex. We have just proved that $M_c(\alpha x + (1-\alpha)y) \le t = \alpha a + (1-\alpha) b$, and this for all $a \ge M_c(x), b \ge M_c(y)$, such that $\frac xa, \frac yb \in dom(M_c)$. If we take the $\inf$ we respect to $a$ and $b$ we find that
$$M_c(\alpha x + (1-\alpha)y) \le \alpha M_c(x) + (1-\alpha) M_c(y)$$
and the function $M_c$ is convex.

2.
   
#+begin_thm
     $\forall a > 0 \; M_c(a x) = \inf \{ t > 0 | \frac {ax}t \in C\} =  \inf \{ t > 0 | \frac {x}{t/a} \in C\} = a  \inf \{ \frac{t}a > 0 | \frac {x}{t/a} \in C\} = a M_c(a)$
#+end_thm


#+begin_thm
      $M_c(-x) = \inf \{ t > 0 | \frac {-x}t \in C\} = \inf \{ t > 0 | \frac {x}t \in C\} = M_C(x)$ because $x \in C \iff -x \in C$
#+end_thm
       
     $M_C$ is a norm, indeed:
     
   - $dom(M_C) = \mathbb R^n$: $C$ has non empty interior, so it contains a ball $B(x, \varepsilon)$, by symmetry it contains also $B(-x, \varepsilon)$. Let's prove that it contain $B(0, \varepsilon)$, for this, consider $y \in \mathbb R^d$ whose norm is smaller than $\varepsilon$, then $y = \frac12 \underbrace{(x + y)}_{\in B(x, \varepsilon)} + \frac12 \underbrace{(-x + y)}_{\in B(-x, \varepsilon)} \in C$. Now for $z \in \mathbb{R}^d$, $\varepsilon\frac{z}{2||z||} \in B(0, \varepsilon) \subseteq C$, and therefore $z \in dom(M_C)$
   - Triangular inequlity:
     \begin{align*}
     M_C(x+y) &= 2 M_C(\frac12 x + \frac12 y)  &\text{(Lemma 1)}
     \\&\le 2 (\frac12 M_C(x) + \frac12 M_C(y)) &\text{(Convexity)}
     \\&= M_C(x) + M_C(y)
     \end{align*}
   - Zero vector: Let $x$ be such that $M_C(x) = 0$, this implies that there exist a sequence $t_n \downarrow 0$ such that $\frac{x}{t_n} \in C$. $C$ being compact, there exist a subsequence $\frac x{t_{n_k}}$ that converges to $x_0 \in C$. If $x \ne 0$ then $||x_0|| = ||x|| \lim \frac1{t_{n_k}} = \infty$ would be a contradiction, so $x = 0$.
   - Absolute homogeneity: Let $x \in C$, $a \in \mathbb{R}$ and let's prove $M_C(ax) = |a|M_C(x)$.
     
     - For the case $a = 0$ look at previous point
     - For $a > 0$ look at lemma 1.
     - For $a < 0$, $M_C(ax) = M_C( (-a) -x) \underbrace{=}_{lemma 1} (-a) M_C(-x) = |a| M_C(-x) \underbrace{=}_{\text{lemma 2}} |a| M_C(x)$.

     
     Let's prove that the unit ball $B$ is equal to $C$: 
     - Let $x$ such that $M_C(x) \le 1$, and let $t_n$ a non-increasing sequence to $M_C(x)$ such that $\frac{x}{t_n} \in C$, by compactness of $C$ the limit $\frac{x}{M_C(x)} \in C$. By convexity of $C$, $x = M_C(x) \frac{x}{M_C(x)} + (1-M_C(x)) 0 \in C$.
     - if $x \in C$, then $M_C(x) \le 1$ because $\frac x1 \in C$
2. convex $\implies$ quasi convex. (Seen in class)
   
   Let's now consider that $p(x)$ is even degree quasi convex and homogeneous. Then:
   - $\forall t > 0$, $p(t x) = t^d p(x)$
   - $p(x) \ge 0$, because otherwise if there exist $x$ such that $p(-x) = p(x) < 0$, then $p(0) = p(\frac12 x - \frac12 x)$ should be negative because $\{u, p(u) \le p(x)\}$ is convexe because $p(x)$ is quasi convex.
   - $Q := \{ x, p(x) \le 1 \}$ is convex.
   $p(x) = \inf\{ t > 0 | \frac{p(x)}{t} \le 1\} = \inf\{ t > 0 | p(\frac{x}{t^{\frac1d}}) \le 1\} = \inf\{ t > 0 | \frac{x}{t^{\frac1d}} \in Q\} = \inf\{ t > 0 | \frac{x}{t} \in Q\}^d = M_Q(x)^d$
   so $p(x)$ is convex as a composition of the non negative convex function $M_Q$ and the non-decreasing convex function on $[0, \infty)$ $t \rightarrow t^d$
   
* Problem 3
Let $A$ be a double sotchastic matrix. Let $G = (U_1\times U_2, V, E)$ be the associated bipartite graph as follow:
- $U_1 = U_2 = \{1, \ldots, n\}$ the set of nodes.
- $E = \{e_{ij} = 1_{a_{ij} > 0}\}$ the set of edges where $e_{ij} = 1$ if the nodes $i \in U_1$ and $j \in U_2$ are connected.
- Let $B$ be the associated incidence matrix.
The feasible set to the relaxed maximum matching program ( program (3) in note 6) is a bounded polyhedral, so the optimal value is attained in one of the vertices. Since the incidence matrix is TUM (seen in class), there exist an integral solution that we represent by $P \in \mathbb R^{n^2}$ where $P_{ij} = 1$ if and only if the two nodes $i$ and $j$ are connected in the solution.

To see that $P$ is in fact a perfect matching, consider the feasible solution $A'$ that gives to each edge $e_{ij}$ the value $a_{ij}$:

- It is feasible by construction of the graph $G$
-  The value of this solution is exactly $n$ because the matrix is doubly stochastic.
- By maximality of $P$, the sum of its entries should also sum up to at least $n$. Since each column and row of $P$ contains at most one $1$, it should actually contain exactly one (otherwise theeir sum would be strictly smaller than $n$).  $\implies P$ is a permutation.
  

let $\alpha \le 1$ be maximal real number verifying $A_1 := A - \alpha P \ge 0$. It is easy to see that:
- $\alpha \ne 0$ because by construction of the graph $G$, each non zero entry $P_{ij}$ of $P$ corresponds to a non zero entry $a_{ij}$ in $A$.
- If $\alpha = 1$ we are done. We assume that $\alpha > 0$
- $\frac{A_1}{1-\alpha}$ is doubly stochastic.
- $\frac{A_1}{1-\alpha}$ contains at least one additional zero than $A$.

By induction on the number of zeros on the matrix, apply the same technique recuresvely to $A_1$ until one of the $\alpha$s is 1 to obtain the convex decomposition $\frac{A_1}{1-\alpha} = \sum_{i=1}^d \alpha_i P_i$ where all the $P_i$ are permutations, and conclude by noticing that:
$$A = \sum_{i=1}^d \frac{\alpha_i}{1-\alpha} P_i + \alpha P$$


* Problem 4

  *The if part:*
  
  #+begin_thm
  Let's assume that $A$ is TUM. Then  $A_1 = (A \; ; \; -I_n )$ where $I_n$ is the $n \times n$ identity matrix is also TUM.
  #+end_thm
   #+begin_proof
  Indeed:
  - take a submatrix of $A_1$, if doesn't contain a cloumn coming from $-I_n$, then we are done, if it does:
  -  let $m$ denote the number of such columns. Develop the determinant of the submatrix with respect to one of them. We see immediately that it is equal to the determinant of a submatrix of $A_1$ containing $m-1$ columns coming from $-I_n$
  -  We conclude by induction on the dimension of $A_1$
#+end_proof
   
  Now we can write:
  \[\{ x | x \ge 0 Ax \le b\} = \{ x |  (A \; ; \; -I ) x \le \begin{pmatrix}b \\ 0\end{pmatrix}  \}\]

  We proved in class that the vertices of the RHS are integrale if $b$ is integrale, and vertices (or extreme points) don't depend on the actual description of the polyhedron.

  *The only if part:*
  
  Let's now assume that $A$ is not TUM, and let's prove that there exist of $b$ for which the polyhedron is not integrale.

  First, let's prove two lemmas:
    #+begin_thm
    $A$ not TUM $\implies$ there exist a submatrix of size $n \times n$ that of \[ C := \begin{pmatrix}A \\ -I_n\end{pmatrix} \]  has determinant not in $\{0, 1, -1\}$ 
  #+end_thm

    #+begin_proof
    Let's assume $A$ is not $TUM$, then there exist $A_1$ a submatrix of B that has determinant not in $\{0, 1, -1\}$.

    Notation:
    - Let's call $p$ the size of $A_1$. If $p = n$ we are done, so let's assume $p < n$.
    - Let's call $c_1 < \ldots c_p$, (resp $r_1 < \ldots r_p$) the indices corresponding to the columns (resp rows) used to construct $A_1$.
      $(A_1)_{jk} = C_{r_j, c_k}$
    - $c_{p+1} < \ldots < c_n$ are the indices the column in $C$ not used in $A_1$
    - $r_{p+j} = c_{p+j}$ for $j = 1 \ldots (n-p)$, e.g.  the indices of rows in $-I_n$ that have $1$ in the $c_{p+j}$ place:
      $C_{r_{p+j}, c_{p+k}} = -\delta_{jk}$
      
    Construct the submatrix $A_2$ of $C$ of size $n$ by doing taking the all the columns $c_1, \ldots c_n$ from $C$ and the rows $r_1 \ldots r_n$, if we rearrange the order of the columns in $A_2$ we get this:

    \[    \begin{pmatrix}    \begin{array}{c}r_1 \\ \vdots\\ r_p \end{array} \left\{\right. &  \underbrace{A_1}_{c_1, \ldots c_p} & * \\   \begin{array}{c}r_{p+1} \\ \vdots\\ r_n \end{array} \left\{\right. &  0 & \underbrace{-I_{n-p}}_{c_{p+1}, \ldots c_n} \\    \end{pmatrix}    \]

    
      
    By developping the determinant of $A_2$ with respect to the last rows we can see it is equal to $(-1)^{n-p}\det(A_1)$, so different from $1, -1, 0$.
    We have just construct a matrix whose determinant is not in  $\{0, 1, -1\}$ and is bigger than $\tilde A$. Contradiction.
  #+end_proof


  #+begin_thm
  $det(M) \not \in \{1, 0, -1\} \implies (\exists t \in \mathbb R^n)\; M^{-1}t \text{ integrale with } t \text{ not integrale }$
  #+end_thm
  
  #+begin_proof
  Assume that $det(M) \not \in \{1, 0, -1\}$.
  Then the $det(M^{-1}) = \frac1{ det(M) } \not \in \mathbb{Z}$, then there exist an entry $a_{ij}$ in $M^{-1}$ that is not integer.
  Let $u$ be the vector with zeros except  the $i^{th}$ entry which is equal to $1$, then $M^{-1}u$ is not integer because $M^{-1}u = m_{ij}$, but $M \underbrace{(M^{-1} u)}_{t}$ is integer.
  #+end_proof

  Back to the proof.


  By using the first Lemma, there exist a submatrix $\tilde C$ of $C$ of size $n \times n$ such that $\det(\tilde C) \not \in \{0, 1, -1\}$. Let's call $r_1, \ldots r_n$ the indices of the rows used in that construction.

  Using the second lemma, there exist an non integrale vector $t$ such that $\tilde C t$ is integrale, so $Ct$ contains at least $n$ integrale componenets. 

  Let $\tilde b = \lceil Ct \rceil$, where $\lceil.\rceil$ is the component wise ceiling to nearest integer.
  It is clear that: $ Ct \le \tilde b$ with at least $n$ tight constraints.
  Let's write $\begin{pmatrix} b_1 \\b_2\end{pmatrix} = \tilde b$ where $b_1 \in \mathbb R^n$,  $b_2 \in \mathbb R^m$.
  We have just proved that:

  $\underbrace{\{ x \in \mathbb R^{n} |  Cx \le \tilde b\}}_{P} = \{ x \in \mathbb R^{n} | x \ge b_2, \; Ax \le  b_1\}$ has a non integrale vertex.

  The polyhedron $\underbrace{\{ x | x \ge 0 Ax \le (b_1 - Ab_2)\}}_{P_2}$ is obtained by translating $P$ with the images of the translation whose vector is $b_2$, so it vertices are the image of the vertices of $P$ by the translation $b_2$. In particular, Since $t - b_2$ is a vertex of $P_2$.

  Now we have that:
  - $b_1 - Ab_2$ is integrale because $b_1, b_2, A$ are integrale
  - $t - b_2$ is not integrale because $t$ is not integrale and $b_2$ is integrale
  - $\implies P_2$ has  integrale vertex.  

  Which ends the proof.





























