\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{amsfonts}

\newcommand{\union}[1]{\underset{#1}{\cup} }
\newcommand{\bigunion}[1]{\underset{#1}{\bigcup} \, }
\newcommand{\inter}[1]{\underset{#1}{\cap} }
\newcommand{\biginter}[1]{\underset{#1}{\bigcap} }
\newcommand{\minimize}[3]{\optimize{#1}{#2}{#3}{min}}
\newcommand{\maximize}[3]{\optimize{#1}{#2}{#3}{max}}
\newcommand{\esp}{{\mathbb E}}
\newcommand{\pr}{{\mathbb P}}
\newcommand{\norm}[1]{\Vert #1 \Vert}
\newcommand{\fnorm}[1]{\Vert #1 \Vert_F}
\newcommand{\nucnorm}[1]{\Vert #1 \Vert_*}
\newcommand{\opnorm}[1]{\Vert #1 \Vert_{op}}
\newcommand{\inner}[2]{\langle #1 \, , \, #2 \rangle}
\newcommand{\row}[2]{\begin{pmatrix}#1 & #2\end{pmatrix}}


\begin{document}

\begin{itemize}
\item
  Let's assume  $X\beta_1 \ne X\beta_2$.
  
  Let $f^*$ be the optimal value, $\alpha = \frac12$, $\beta_{\alpha} = \alpha \beta_1 + (1-\alpha) \beta_2$.
  Then, by the convexity of $\norm{.}_2^2, \norm{.}_1$:
  \begin{align*}
    f^* &\le ||Y - X \beta_{\alpha}||_2^2 + \lambda ||\beta_{\alpha}||_1
    \\&= \norm{ \alpha (Y - X \beta_1) + (1-\alpha)(Y - X\beta_2)}_2^2
      + \lambda \norm{\alpha \beta_1 + (1-\alpha)\beta_2}_1
    \\&<
      \alpha \left(||Y - X \beta_1||_2^2 + \lambda ||\beta_1||_1\right)
        + (1-\alpha)\left(||Y - X \beta_2||_2^2 + \lambda ||\beta_2||_1\right)p
        &\text{(By strict convexity of $\norm{.}_2^2$)}
    \\&\le f^*
  \end{align*}
  Contradicition.
  
\item
  ${\cal L}(\beta^*, \lambda) = \frac12 \norm{Y-X\beta}_2^2 + \lambda \norm{\beta}_1$

  Let $(\beta^*, \lambda^*)$ be an optimal solution, then $0 \in \partial_{\lambda} L (\beta^*, \lambda^*)$

  $\partial_{\lambda^*} L (\beta, \lambda^*) = \{ -X^T(Y-X\beta) +  \lambda^* \sum_{\beta_i \ne 0} sign(\beta_i) e_i + \lambda^* \sum_{\beta_i = 0}  \alpha_i e_i : \alpha \in [-1, 1] \}$

  so there exist $\norm{\alpha}_{\infty} \le 1$ such that $-X^T(Y-X\beta) +  \lambda^* \sum_{\beta_i \ne 0} sign(\beta_i) e_i + \lambda^* \sum_{\beta_i = 0}  \alpha_i e_i = 0$
  
  Coordinate wise, this gives for all $j$:
  
  $ -X_j^T (Y - X\beta) + \lambda sign(\beta_j) = 0$ if $\beta_j \ne 0$
  
  $ X (Y - X\beta)e_j + \lambda \alpha_i sign(\beta_j) = 0$ if $\beta_j = 0$
  
  e.g
  
  $ \lambda^* = -sign(\beta_j^*) X_j^T(Y - X\beta^*)$ if $\beta_j^* \ne 0$
  
  $ \lambda^* \ge |2  X_j^T(Y - X\beta^*)|$ if $\beta_j^* = 0$
  
  
\item
  Let $\hat \beta$ be an optimal solution. Let $\chi = \{ j, \hat \beta_j \ne 0 \}$, and let's suppose it is non empty.
  Let $j$ such that $\hat \beta_j > 0$ (If such $j$ exists)
  By 2.2,  $\lambda = X_j^T (Y - X \hat \beta)$, but since $\lambda > \norm{X^TY}_{\infty} \ge X_j^TY$, then $X_j^TX\hat \beta > 0$
  Similarly, if there for $j$ such that $\hat \beta < 0$, $X_j^TX\hat \beta < 0$.
  c/c $\beta_j \ne 0 \implies \beta_j X_j^TX\hat \beta > 0$

  
  \begin{align*}
    \frac12 \norm{Y - X\beta}_2^2 + \lambda \norm{\beta}_1
    &= \frac12 \norm{Y}_2^2 - \hat \beta^TX^TY + \frac12 \beta^T X^TX \hat \beta +  \lambda \sum_{i \in \chi} |\hat \beta_i|
    \\&\ge \frac12 \norm{Y}_2^2 + \sum_{i \in \chi} |\hat \beta_i| (\lambda - |X_i^TY|)
        + \frac12  \underbrace{\sum_{i \in \chi} \hat\beta_i X_i^TX\hat \beta}_{> 0}
    \\&> \frac12 \norm{Y}_2^2
    \\&= \frac12 \norm{Y - X0}_2^2 + \lambda\norm{0}_1
  \end{align*}
  Contradiction, so $\hat \beta = 0$
\item
  $$\lambda \in [\lambda_0, \lambda_1]$$
  Let $\chi(\lambda) = \{ j, \hat \beta_j(\lambda) \ne 0 \} := \chi$, $r = |\chi|$ (doesn't depend on $\lambda$ by assumption)

  We have proved in 2.2 that for all there exist $\gamma(\lambda) \in \mathbb R^r$, such that:
  $X_{\chi}^T(Y - X\hat \beta(\lambda)) = \lambda \gamma(\lambda) $ where  $\gamma(\lambda)_i = sign(\hat \beta(\lambda)_i), i \in \chi$.

  $\gamma := \gamma(\lambda)$ doesn't depend on $\lambda$ either.

  $X_{\chi}^T(Y - X\hat \beta(\lambda)) =  \lambda \gamma$

  It is easy to see that the KKT conditions in 2.2 are actualy necessary and sufficient (because we are minimizing a convexe function), since we are assuming uniqueness, $\hat \beta(\lambda)$ is the unique solution to :
  \begin{equation}
    \left\{
      \begin{array}{c}
        X_{\chi}^T(Y - X\hat \beta(\lambda)) =  \lambda \gamma\\
        \hat \beta(\lambda)_{\chi^c} = 0
      \end{array}
    \right.
  \end{equation}

  Let $\gamma_0$ be equal to $\gamma$ on $\chi$ and to 0 otherwise.
  Let $\lambda = \hat \beta(\lambda_0) - (\lambda - \lambda_0) \gamma_0$, it is easy to see that $\lambda_{\chi^c} = 0$ and that:
  $X_{\chi}^T(Y - X\alpha) = \underbrace{X_{\chi}^T(Y - X\hat \beta(\lambda_0))}_{\lambda_0 \gamma} + (\lambda - \lambda_0) X_{\chi}^T X \gamma_0$

  $X_{\chi}^T X \gamma_0 = X_{\chi}^T X_{\chi} \gamma$
\end{itemize}
\end{document}



















